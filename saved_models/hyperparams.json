{
    "model_type": "attention",
    "wordvec_size": 16,
    "hidden_size": 256,
    "learning_rate": 0.01,
    "batch_size": 32,
    "max_epoch": 10,
    "vocab_size": 23
}